{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis\n",
    "\n",
    "This contest is taken from the real task of Text Processing.\n",
    "\n",
    "The task is to build a model that will determine the tone (neutral, positive, negative) of the text. To do this, you will need to train the model on the existing data (train.csv). The resulting model will have to determine the class (neutral, positive, negative) of new texts (test data that were not used to build the model) with maximum accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"C:/Users/heera/Desktop/GLabs_DSMP_New-masters/twitter/train.csv\",encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99984</td>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>@Cupcake  seems like a repeating problem   hop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99985</td>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake__ arrrr we both replied to each other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99986</td>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>@CuPcAkE_2120 ya i thought so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99987</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>@Cupcake_Dollie Yes. Yes. I'm glad you had mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99988</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake_kayla haha yes you do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText\n",
       "0           1          0                       is so sad for my APL frie...\n",
       "1           2          0                     I missed the New Moon trail...\n",
       "2           3          1                            omg its already 7:30 :O\n",
       "3           4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4           5          0           i think mi bf is cheating on me!!!   ...\n",
       "...       ...        ...                                                ...\n",
       "99984   99996          0  @Cupcake  seems like a repeating problem   hop...\n",
       "99985   99997          1  @cupcake__ arrrr we both replied to each other...\n",
       "99986   99998          0                     @CuPcAkE_2120 ya i thought so \n",
       "99987   99999          1  @Cupcake_Dollie Yes. Yes. I'm glad you had mor...\n",
       "99988  100000          1                    @cupcake_kayla haha yes you do \n",
       "\n",
       "[99989 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions for EDA\n",
    "\n",
    "1. Total words in corpus\n",
    "2. Total unique words in corpus without pre-processing\n",
    "3. Total unique words in corpus after lowercase\n",
    "4. Total unique words in corpus after lowercase, stemming / lemmatization\n",
    "5. Total unique words in corpus after lowercase, stemming / lemmatization and stopwords removal\n",
    "6. Prepricessing steps - CHALLENGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total words in corpus\n",
    "\n",
    "def total_tokens_raw(tweet):\n",
    "    \"\"\"\n",
    "    Find total raw tokens\n",
    "    \n",
    "    Args:\n",
    "    tweet - str - tweet text\n",
    "    \n",
    "    Returns:\n",
    "    int - count of tokens in the tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(word_tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add count of raw tokens in twitter DF\n",
    "\n",
    "tweets['raw_tokens_count'] = tweets['SentimentText'].map(total_tokens_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>raw_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText  \\\n",
       "0       1          0                       is so sad for my APL frie...   \n",
       "1       2          0                     I missed the New Moon trail...   \n",
       "2       3          1                            omg its already 7:30 :O   \n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4       5          0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "   raw_tokens_count  \n",
       "0                12  \n",
       "1                 7  \n",
       "2                 6  \n",
       "3                31  \n",
       "4                12  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw tokens are - 1720314\n"
     ]
    }
   ],
   "source": [
    "# Total tokens in the corpus\n",
    "\n",
    "print('Total raw tokens are - {}'.format(sum(tweets['raw_tokens_count'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unqiuq tokens are - 133560\n"
     ]
    }
   ],
   "source": [
    "# Total unique words in corpus\n",
    "\n",
    "\"\"\"\n",
    "Steps:\n",
    "------\n",
    "\n",
    "1. Combining all the tweets\n",
    "2. Work tokenization on the tweets\n",
    "3. Create a set\n",
    "4. Find lenth of the set\n",
    "\"\"\"\n",
    "\n",
    "# 1. Combining all the tweets\n",
    "combined_tweets = ' '.join(tweets['SentimentText'])\n",
    "\n",
    "# 2. Work tokenization on the tweets\n",
    "tokenized_tweets = word_tokenize(combined_tweets)\n",
    "\n",
    "# 3. Create a set\n",
    "set_tokenized_tweets = set(tokenized_tweets)\n",
    "\n",
    "# 4. Find lenth of the set\n",
    "\n",
    "print('Total unqiuq tokens are - {}'.format(len(set_tokenized_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unqiue lower-case tokens are - 117940\n"
     ]
    }
   ],
   "source": [
    "# Total unique words in corpus after lowercase\n",
    "\n",
    "print('Total unqiue lower-case tokens are - {}'.format(len(set(word_tokenize(combined_tweets.lower())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case and stem the tweet\n",
    "\n",
    "def lower_stem_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Lower cases and applies stemming\n",
    "    \n",
    "    Args:\n",
    "    tweet - str - tweet text\n",
    "    \n",
    "    Returns:\n",
    "    str - lower cased and stemmed tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return ' '.join([ps.stem(tok) for tok in word_tokenize(tweet.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unqiue lower-case and stemmed tokens are - 107045\n"
     ]
    }
   ],
   "source": [
    "# Total unique words in corpus after lowercase and stemming\n",
    "\n",
    "# Lower cased and stemmed tweets\n",
    "combined_lc_st_tweets = ' '.join([lower_stem_tweet(tweet) for tweet in tweets['SentimentText']])\n",
    "\n",
    "print('Total unqiue lower-case and stemmed tokens are - {}'.format(len(set(word_tokenize(combined_lc_st_tweets)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load english stop words\n",
    "\n",
    "stops = (stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unqiue lower-case, stemmed and stop words excludedf tokens are - 106919\n"
     ]
    }
   ],
   "source": [
    "# Total unique words in corpus after lowercase, stemming and stop words removal\n",
    "\n",
    "print('Total unqiue lower-case, stemmed and stop words excludedf tokens are - {}'.format(len(set([w for w in word_tokenize(combined_lc_st_tweets) if w not in stops]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing for twitter data\n",
    "\n",
    "1. Hashtags\n",
    "2. Mentions (@)\n",
    "3. Tagging ID\n",
    "4. Numbers\n",
    "5. Punctuation & Special Characters\n",
    "6. Smileys\n",
    "7. Emojis\n",
    "8. Links (http:// or https://) & Short links (t.co)\n",
    "9. HTML tags\n",
    "10. Timestamp\n",
    "11. Dates\n",
    "12. Images (<img alt=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1234 \n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer('^\\d+\\s|\\s\\d+$|\\s\\d+\\s', 'this is me @sagar21. how are you? this is @amit. #learning 1234 on 21/12/2019 at t.co/www.ga.com', flags=re.M):\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is me __mention__. how are you? this is __mention__'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('@\\w+', '__mention__', 'this is me @sagar21. how are you? this is @amit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying hashtags, mentions and links\n",
    "\n",
    "def normalize_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Lower cases and normalizes tweet\n",
    "    \n",
    "    Args:\n",
    "    tweet - str - tweet text\n",
    "    \n",
    "    Returns:\n",
    "    str - lower cased and stemmed tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lower case the tweet\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Substitute mentions\n",
    "    tweet = re.sub('@\\w+', '__mention__', tweet)\n",
    "    \n",
    "    # Substitute hashtags\n",
    "    tweet = re.sub('#\\w+', '__hashtag__', tweet)\n",
    "    \n",
    "    # Substitute dates\n",
    "    tweet = re.sub('\\d\\d\\/\\d\\d\\/\\d\\d\\d\\d', '__date__', tweet)\n",
    "    \n",
    "    # Substitute links\n",
    "    tweet = re.sub('http.*|https.*|t.co\\/.*', '__link__', tweet)\n",
    "    \n",
    "    # Substitute numbers\n",
    "    tweet = re.sub('^\\d+\\s|\\s\\d+$|\\s\\d+\\s', '__number__', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['norm_tweet'] = tweets['SentimentText'].map(normalize_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>raw_tokens_count</th>\n",
       "      <th>norm_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>#3turnoffwords this shit sucks</td>\n",
       "      <td>5</td>\n",
       "      <td>__hashtag__ this shit sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>#asylm J2 panel is over. Guess it's back to n...</td>\n",
       "      <td>15</td>\n",
       "      <td>__hashtag__ j2 panel is over. guess it's back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>#poemsunder140 ....started by @shannonelyse1</td>\n",
       "      <td>7</td>\n",
       "      <td>__hashtag__ ....started by __mention__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>#squarespace brighten my bad day! i never win...</td>\n",
       "      <td>12</td>\n",
       "      <td>__hashtag__ brighten my bad day! i never win ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>#Susan Boyle didnt win! mh well, diversity wa...</td>\n",
       "      <td>18</td>\n",
       "      <td>__hashtag__ boyle didnt win! mh well, diversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99967</td>\n",
       "      <td>99979</td>\n",
       "      <td>1</td>\n",
       "      <td>@ctcash @buildingateam @diabetescure @chocolat...</td>\n",
       "      <td>23</td>\n",
       "      <td>__mention__ __mention__ __mention__ __mention_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99971</td>\n",
       "      <td>99983</td>\n",
       "      <td>0</td>\n",
       "      <td>@CTerry1985 That's the thing; the new raft of ...</td>\n",
       "      <td>22</td>\n",
       "      <td>__mention__ that's the thing; the new raft of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99973</td>\n",
       "      <td>99985</td>\n",
       "      <td>1</td>\n",
       "      <td>@ctham  #FollowFriday</td>\n",
       "      <td>4</td>\n",
       "      <td>__mention__  __hashtag__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99974</td>\n",
       "      <td>99986</td>\n",
       "      <td>0</td>\n",
       "      <td>@ctham #awaresg You are not wrong. But from a ...</td>\n",
       "      <td>33</td>\n",
       "      <td>__mention__ __hashtag__ you are not wrong. but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99976</td>\n",
       "      <td>99988</td>\n",
       "      <td>1</td>\n",
       "      <td>@ctham @Wilsurn Trying to get a wider range of...</td>\n",
       "      <td>25</td>\n",
       "      <td>__mention__ __mention__ trying to get a wider ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5995 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText  \\\n",
       "131       132          0                     #3turnoffwords this shit sucks   \n",
       "132       133          0   #asylm J2 panel is over. Guess it's back to n...   \n",
       "133       134          1       #poemsunder140 ....started by @shannonelyse1   \n",
       "134       135          0   #squarespace brighten my bad day! i never win...   \n",
       "135       136          0   #Susan Boyle didnt win! mh well, diversity wa...   \n",
       "...       ...        ...                                                ...   \n",
       "99967   99979          1  @ctcash @buildingateam @diabetescure @chocolat...   \n",
       "99971   99983          0  @CTerry1985 That's the thing; the new raft of ...   \n",
       "99973   99985          1                              @ctham  #FollowFriday   \n",
       "99974   99986          0  @ctham #awaresg You are not wrong. But from a ...   \n",
       "99976   99988          1  @ctham @Wilsurn Trying to get a wider range of...   \n",
       "\n",
       "       raw_tokens_count                                         norm_tweet  \n",
       "131                   5                        __hashtag__ this shit sucks  \n",
       "132                  15   __hashtag__ j2 panel is over. guess it's back...  \n",
       "133                   7             __hashtag__ ....started by __mention__  \n",
       "134                  12   __hashtag__ brighten my bad day! i never win ...  \n",
       "135                  18   __hashtag__ boyle didnt win! mh well, diversi...  \n",
       "...                 ...                                                ...  \n",
       "99967                23  __mention__ __mention__ __mention__ __mention_...  \n",
       "99971                22  __mention__ that's the thing; the new raft of ...  \n",
       "99973                 4                           __mention__  __hashtag__  \n",
       "99974                33  __mention__ __hashtag__ you are not wrong. but...  \n",
       "99976                25  __mention__ __mention__ trying to get a wider ...  \n",
       "\n",
       "[5995 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['SentimentText'].str.contains('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Process\n",
    "\n",
    "1. Import CountVectorizer\n",
    "2. Create X & Y\n",
    "3. Create train and test dataset (train_test_split required)\n",
    "4. Fit & Transform vecotrs using X_train and just transform X_test\n",
    "5. Fit model\n",
    "6. predict\n",
    "7. Print CLF report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "\n",
    "X = tweets['SentimentText']\n",
    "y = tweets['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2178: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split data in to train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform vectors for X_train\n",
    "\n",
    "X_train_vec = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_test to vectors\n",
    "\n",
    "X_test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate models\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "vot_hard = VotingClassifier([('rf', rf), ('lr', lr)], voting='hard')\n",
    "vot_soft = VotingClassifier([('rf', rf), ('lr', lr)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68     13064\n",
      "           1       0.76      0.73      0.74     16933\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     29997\n",
      "   macro avg       0.71      0.71      0.71     29997\n",
      "weighted avg       0.72      0.72      0.72     29997\n",
      "\n",
      "\n",
      "Logistic Regression Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73     13064\n",
      "           1       0.78      0.82      0.80     16933\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     29997\n",
      "   macro avg       0.77      0.76      0.76     29997\n",
      "weighted avg       0.77      0.77      0.77     29997\n",
      "\n",
      "\n",
      "Voting Classifier Hard Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73     13064\n",
      "           1       0.83      0.68      0.74     16933\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     29997\n",
      "   macro avg       0.75      0.75      0.74     29997\n",
      "weighted avg       0.76      0.74      0.74     29997\n",
      "\n",
      "\n",
      "Voting Classifier Soft Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73     13064\n",
      "           1       0.78      0.83      0.80     16933\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     29997\n",
      "   macro avg       0.77      0.76      0.76     29997\n",
      "weighted avg       0.77      0.77      0.77     29997\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict\n",
    "\n",
    "print('Random Forest Results')\n",
    "print('---------------------')\n",
    "rf.fit(X_train_vec, y_train)\n",
    "y_pred = rf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Logistic Regression Results')\n",
    "print('---------------------')\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Hard Results')\n",
    "print('---------------------')\n",
    "vot_hard.fit(X_train_vec, y_train)\n",
    "y_pred = vot_hard.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Soft Results')\n",
    "print('---------------------')\n",
    "vot_soft.fit(X_train_vec, y_train)\n",
    "y_pred = vot_soft.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2178: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68     13064\n",
      "           1       0.76      0.72      0.74     16933\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     29997\n",
      "   macro avg       0.71      0.71      0.71     29997\n",
      "weighted avg       0.72      0.71      0.72     29997\n",
      "\n",
      "\n",
      "Logistic Regression Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72     13064\n",
      "           1       0.77      0.82      0.80     16933\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     29997\n",
      "   macro avg       0.76      0.76      0.76     29997\n",
      "weighted avg       0.76      0.76      0.76     29997\n",
      "\n",
      "\n",
      "Voting Classifier Hard Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.73     13064\n",
      "           1       0.83      0.66      0.74     16933\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     29997\n",
      "   macro avg       0.74      0.74      0.73     29997\n",
      "weighted avg       0.75      0.73      0.73     29997\n",
      "\n",
      "\n",
      "Voting Classifier Soft Results\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72     13064\n",
      "           1       0.78      0.82      0.80     16933\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     29997\n",
      "   macro avg       0.76      0.76      0.76     29997\n",
      "weighted avg       0.77      0.77      0.77     29997\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create X & y\n",
    "\n",
    "X = tweets['norm_tweet']\n",
    "y = tweets['Sentiment']\n",
    "\n",
    "# Split data in to train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)\n",
    "\n",
    "# Fit and transform vectors for X_train\n",
    "\n",
    "X_train_vec = cv.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test to vectors\n",
    "\n",
    "X_test_vec = cv.transform(X_test)\n",
    "\n",
    "# Fit and predict\n",
    "\n",
    "print('Random Forest Results')\n",
    "print('---------------------')\n",
    "rf.fit(X_train_vec, y_train)\n",
    "y_pred = rf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Logistic Regression Results')\n",
    "print('---------------------')\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Hard Results')\n",
    "print('---------------------')\n",
    "vot_hard.fit(X_train_vec, y_train)\n",
    "y_pred = vot_hard.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Soft Results')\n",
    "print('---------------------')\n",
    "vot_soft.fit(X_train_vec, y_train)\n",
    "y_pred = vot_soft.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2178: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "---------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3b21615620ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Random Forest Results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CountVectorizer with N-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "# Create X & y\n",
    "\n",
    "X = tweets['norm_tweet']\n",
    "y = tweets['Sentiment']\n",
    "\n",
    "# Split data in to train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)\n",
    "\n",
    "# Fit and transform vectors for X_train\n",
    "\n",
    "X_train_vec = cv.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test to vectors\n",
    "\n",
    "X_test_vec = cv.transform(X_test)\n",
    "\n",
    "# Fit and predict\n",
    "\n",
    "print('Random Forest Results')\n",
    "print('---------------------')\n",
    "rf.fit(X_train_vec, y_train)\n",
    "y_pred = rf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Logistic Regression Results')\n",
    "print('---------------------')\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Hard Results')\n",
    "print('---------------------')\n",
    "vot_hard.fit(X_train_vec, y_train)\n",
    "y_pred = vot_hard.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Soft Results')\n",
    "print('---------------------')\n",
    "vot_soft.fit(X_train_vec, y_train)\n",
    "y_pred = vot_soft.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer with N-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "# Create X & y\n",
    "\n",
    "X = tweets['norm_tweet']\n",
    "y = tweets['Sentiment']\n",
    "\n",
    "# Split data in to train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)\n",
    "\n",
    "# Fit and transform vectors for X_train\n",
    "\n",
    "X_train_vec = cv.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test to vectors\n",
    "\n",
    "X_test_vec = cv.transform(X_test)\n",
    "\n",
    "# Fit and predict\n",
    "\n",
    "print('Random Forest Results')\n",
    "print('---------------------')\n",
    "rf.fit(X_train_vec, y_train)\n",
    "y_pred = rf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Logistic Regression Results')\n",
    "print('---------------------')\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Hard Results')\n",
    "print('---------------------')\n",
    "vot_hard.fit(X_train_vec, y_train)\n",
    "y_pred = vot_hard.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "print('Voting Classifier Soft Results')\n",
    "print('---------------------')\n",
    "vot_soft.fit(X_train_vec, y_train)\n",
    "y_pred = vot_soft.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
